{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tom Louwerse stores the raw simulation data that is used to produce the [Peilingwijzer](https://peilingwijzer.tomlouwerse.nl) in a file that can be downloaded via the following dynamic link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://d1bjgq97if6urz.cloudfront.net/Public/Peilingwijzer/Last/coa_seats.csv\",\n",
    "                   index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colors picked from the Peilingwijzer's colors to make the correspondence clearer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    \"VVD\": \"#455493\",\n",
    "    \"PVV\": \"#00B9FF\",\n",
    "    \"CDA\": \"#00894B\",\n",
    "    \"D66\": \"#4AAB2D\",\n",
    "    \"GL\": \"#006B39\",\n",
    "    \"SP\": \"#C73D77\",\n",
    "    \"PvdA\": \"#9A0D1B\",\n",
    "    \"CU\": \"#0094B4\",\n",
    "    \"PvdD\": \"#EBC30A\",\n",
    "    \"50PLUS\": \"#C2791E\",\n",
    "    \"SGP\": \"#7F8084\",\n",
    "    \"Denk\": \"#41BAC1\",\n",
    "    \"FvD\": \"#6E0C13\",\n",
    "    \"PvdT\": \"#F9E518\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_kwargs = dict(\n",
    "#                alpha=0.8,\n",
    "               stacked=True,\n",
    "#                histtype='stepfilled',\n",
    "#                density=True,\n",
    "               figsize=(15,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot.hist(**hist_kwargs, bins=data.max().max() + 1, color=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to visualize coalitions in this way, you have to add up the counts per simulation and then visualize those numbers. For instance, let's take the VVD, PVV, CDA coalition, which at this point in time (10 November 2020) could form a majority, according to the sum of the polls' best estimates as published on the Peilingwijzer graph. And we compare to a huge left-wing-ish coalition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalitions = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_coalition(data, *parties):\n",
    "    return sum(data[party] for party in parties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coalition(coalitions_df, data, *parties, inplace=False):\n",
    "    name = \"+\".join(parties)\n",
    "    if not inplace:\n",
    "        coalitions_df = coalitions_df.copy()\n",
    "    coalitions_df[name] = sum_coalition(data, *parties)\n",
    "    return coalitions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalitions = add_coalition(coalitions, data, \"VVD\", \"PVV\", \"CDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalitions = add_coalition(coalitions, data, \"GL\", \"SP\", \"PvdA\", \"PvdD\", \"Denk\", \"50PLUS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalitions.plot.hist(\n",
    "    **hist_kwargs,\n",
    "    bins=coalitions.max().max() + 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to still extract 95% confidence intervals. We can approximate by using mean and twice the standard deviation. Then round up, as is done in Peilingwijzer as well. Let's try it out for a few parties and see whether it matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import namedtuple\n",
    "Peiling = namedtuple('Peiling', ['verwacht', 'laag', 'hoog'])\n",
    "with open('peilingen.pkl', 'rb') as fh:\n",
    "    numbers = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_estimator_1(party):\n",
    "    est = data[party].mean().round()\n",
    "    interval = math.ceil((2 * data[party].std()))\n",
    "    our_estimate = Peiling(verwacht=est, laag=max(0, est - interval), hoog=min(est + interval, 150))\n",
    "    correct = numbers[party] == our_estimate\n",
    "    return correct, {\"correct\": numbers[party], \"ours\": our_estimate, \"mean\": data[party].mean(), \"2 x std\": 2 * data[party].std()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{party: compare_estimator_1(party) for party in data.columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, not completely there yet, then, but pretty close. Had to add clip below 0 (and, to be technically correct, above 150).\n",
    "\n",
    "But then still there's a few things going wrong:\n",
    "\n",
    "- Denk is not at the mean. Is the peak instead determined at the maximum probability peak?\n",
    "- GL, CU and 50PLUS have a broader confidence interval in our estimate. Perhaps ceil is not the best rounding function. We could fiddle a bit with a weird rounder that rounds up above 0.25 and down below that, or some other value that fits the distributions best.\n",
    "\n",
    "This is probably all due to the gaussian approximation we make here. The actual model is not a Gaussian, so mean and std are flawed estimators of the true confidence interval. Anyway, as long as it's close, we can always try the actual model later.\n",
    "\n",
    "Let's first try to compare max likelihood peak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Denk\"].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_estimator_2():\n",
    "    comparison = {}\n",
    "\n",
    "    def estimate_Peiling(est, std):\n",
    "        interval = math.ceil((2 * std))\n",
    "        return Peiling(verwacht=est, laag=max(0, est - interval), hoog=min(est + interval, 150))\n",
    "\n",
    "    def check_correctness(theirs, ours):\n",
    "        correct = theirs == ours\n",
    "        return correct, {\"correct\": theirs,\n",
    "                         \"ours\": ours,\n",
    "                         \"mean\": data[party].mean(),\n",
    "                         \"2 x std\": 2 * data[party].std()}\n",
    "\n",
    "    def compare_party(party):\n",
    "        est = data[party].value_counts().index[0]\n",
    "        our_estimate = estimate_Peiling(est, data[party].std())\n",
    "        return check_correctness(numbers[party], our_estimate)\n",
    "\n",
    "    for party in data.columns:\n",
    "        comparison[party] = compare_party(party)\n",
    "\n",
    "    # add missing seats if necessary\n",
    "    while sum(ding[1]['ours'].verwacht for ding in comparison.values()) < 150:\n",
    "        rest_values = {party: thing[1][\"mean\"] - thing[1][\"ours\"].verwacht for party, thing in comparison.items()}\n",
    "        party_max_rest = max(rest_values.keys(), key=(lambda k: rest_values[k]))\n",
    "\n",
    "        ours_new = estimate_Peiling(comparison[party_max_rest][1][\"ours\"].verwacht + 1,\n",
    "                                    comparison[party_max_rest][1][\"2 x std\"] / 2)\n",
    "\n",
    "        comparison[party_max_rest] = check_correctness(numbers[party_max_rest], ours_new)\n",
    "\n",
    "    return comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_2 = compare_estimator_2()\n",
    "# comparison_2\n",
    "{party: ding[0] for party, ding in comparison_2.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(ding[1]['correct'].verwacht for ding in comparison_2.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(ding[1]['ours'].verwacht for ding in comparison_2.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, ok, so Denk has to get a rest seat here, it seems.\n",
    "\n",
    "Then, let's try the rounding fiddling to get the rest correct..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_estimator_3(round_dec=0.15):\n",
    "    comparison = {}\n",
    "\n",
    "    def estimate_Peiling(est, std, round_dec=round_dec):\n",
    "        two_std = 2 * std\n",
    "        two_std_floor = math.floor(two_std)\n",
    "        two_std_rest = two_std - two_std_floor\n",
    "        if two_std_rest < round_dec:\n",
    "            interval = two_std_floor\n",
    "        else:\n",
    "            interval = math.ceil(two_std)\n",
    "        return Peiling(verwacht=est, laag=max(0, est - interval), hoog=min(est + interval, 150))\n",
    "\n",
    "    def check_correctness(theirs, ours):\n",
    "        correct = theirs == ours\n",
    "        return correct, {\"correct\": theirs,\n",
    "                         \"ours\": ours,\n",
    "                         \"mean\": data[party].mean(),\n",
    "                         \"2 x std\": 2 * data[party].std()}\n",
    "\n",
    "    def compare_party(party):\n",
    "        # max likelihood or mean makes no difference in practice\n",
    "#         est = data[party].value_counts().index[0]\n",
    "        est = data[party].mean().round()\n",
    "        our_estimate = estimate_Peiling(est, data[party].std())\n",
    "        return check_correctness(numbers[party], our_estimate)\n",
    "\n",
    "    for party in data.columns:\n",
    "        comparison[party] = compare_party(party)\n",
    "\n",
    "    # add missing seats if necessary\n",
    "    while sum(ding[1]['ours'].verwacht for ding in comparison.values()) < 150:\n",
    "        rest_values = {party: thing[1][\"mean\"] - thing[1][\"ours\"].verwacht for party, thing in comparison.items()}\n",
    "        party_max_rest = max(rest_values.keys(), key=(lambda k: rest_values[k]))\n",
    "\n",
    "        ours_new = estimate_Peiling(comparison[party_max_rest][1][\"ours\"].verwacht + 1,\n",
    "                                    comparison[party_max_rest][1][\"2 x std\"] / 2)\n",
    "\n",
    "        comparison[party_max_rest] = check_correctness(numbers[party_max_rest], ours_new)\n",
    "\n",
    "    return comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_3 = compare_estimator_3()\n",
    "{party: ding[0] for party, ding in comparison_3.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_3['GL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so this is still not perfect, but it's the closest we can get, with only one wrong fit.\n",
    "\n",
    "On the other hand, maybe just using the gaussian approximation with rounding up is a safer way to go. We will have some wider uncertainty estimates, but we can take those to represent the fact that we do not actually use the right model.\n",
    "\n",
    "So, let's go with estimation method 2 for the coalitions. Except, instead of max likelihood, we go back to mean, because it makes no difference in practice, but is unambiguous in case there are two equally likely bins in the histogram.\n",
    "\n",
    "Also, let's do it with Python standard library stuff now to prepare for using it from Heroku with minimal dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_Peiling_from_simulations(simulations):\n",
    "    def estimate_Peiling(est, std):\n",
    "        interval = math.ceil((2 * std))\n",
    "        return Peiling(verwacht=int(est),\n",
    "                       laag=int(max(0, est - interval)),\n",
    "                       hoog=int(min(est + interval, 150)))\n",
    "\n",
    "    est = round(statistics.mean(simulations))\n",
    "    return estimate_Peiling(est, statistics.stdev(simulations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{party: to_Peiling_from_simulations(data[party]) == numbers[party] for party in data.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_Peiling_from_simulations(coalitions[\"GL+SP+PvdA+PvdD+Denk+50PLUS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_Peiling_from_simulations(coalitions[\"VVD+PVV+CDA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was with a Pandas Series, but we can now also do it directly on a regular list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_Peiling_from_simulations(list(coalitions[\"VVD+PVV+CDA\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when we do it for all parties, we should get a vanishing interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalitions = add_coalition(coalitions, data, *data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalitions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_Peiling_from_simulations(list(coalitions[\"VVD+PVV+CDA+D66+GL+SP+PvdA+CU+PvdD+50PLUS+SGP+Denk+FvD+PvdT\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_Peiling_from_simulations(sum_coalition(data, *data.columns[:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, without PvdT (last in the list), which is estimated at 0, but could get 1, this is what you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_Peiling_from_simulations(sum_coalition(data, *data.columns[:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_Peiling_from_simulations(data['FvD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FvD is second to last, so excluding it should indeed lower the estimate by 6. We see that the uncertainty of PvdT alone is no longer just \"added\" as we did before in the first Coalitiewijzer, but they are now combined into an uncertainty estimate that is apparently the same as that of FvD alone.\n",
    "\n",
    "Time to build this into the Coalitiewijzer!\n",
    "\n",
    "Save in native format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_df = pd.read_csv(\"https://d1bjgq97if6urz.cloudfront.net/Public/Peilingwijzer/Last/coa_seats.csv\",\n",
    "                       index_col=0, header=0)\n",
    "sims = {party: tuple(sims_df[party]) for party in sims_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('simulations.pkl', 'wb') as fh:\n",
    "    pickle.dump(sims, fh)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
